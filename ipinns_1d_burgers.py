# -*- coding: utf-8 -*-
"""IPINNs_1D_Burgers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15Lx0BRCXPpzrhFrBhM4FSOGyfuzbmdC-
"""

import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import torch
import torch.nn as nn

# ---------------------- iPINN Model Definition ---------------------- #
class BurgersInversePINN(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(2, 20),
            nn.Tanh(),
            nn.Linear(20, 30),
            nn.Tanh(),
            nn.Linear(30, 30),
            nn.Tanh(),
            nn.Linear(30, 20),
            nn.Tanh(),
            nn.Linear(20, 20),
            nn.Tanh(),
            nn.Linear(20, 1)
        )
        # Learnable log-nu for positivity constraint
        self.log_nu = nn.Parameter(torch.tensor(np.log(0.01 / np.pi), dtype=torch.float32))

    def forward(self, x):
        return self.model(x)

    def viscosity(self):
        return torch.exp(self.log_nu)

# ---------------------- Physics-Informed Loss ---------------------- #
def compute_pde_residual_ipinn(pinn, x, t):
    x.requires_grad_(True)
    t.requires_grad_(True)
    X = torch.cat([x, t], dim=1)
    u = pinn(X)
    grads = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]
    grads_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]
    grads_xx = torch.autograd.grad(grads, x, grad_outputs=torch.ones_like(grads), create_graph=True, retain_graph=True)[0]
    nu = pinn.viscosity()
    f = grads_t + u * grads - nu * grads_xx
    return f

# ---------------------- Data Generation ---------------------- #
def initial_condition(x):
    return -torch.sin(np.pi * x)

def boundary_condition(t):
    return torch.zeros_like(t)

def sample_training_points(n_interior, n_boundary, n_initial):
    x_int = torch.rand(n_interior, 1) * 2 - 1   # [-1,1]
    t_int = torch.rand(n_interior, 1)
    x_bnd = torch.cat([torch.ones(n_boundary//2, 1) * -1, torch.ones(n_boundary//2, 1)], dim=0)
    t_bnd = torch.rand(n_boundary, 1)
    x_ini = torch.rand(n_initial, 1) * 2 - 1
    t_ini = torch.zeros(n_initial, 1)
    return (x_int, t_int), (x_bnd, t_bnd), (x_ini, t_ini)

def sample_observations(nx=50, nt=10):
    """Sample sparse observation points for the inverse problem."""
    x_obs = torch.linspace(-1, 1, nx).reshape(-1, 1)
    t_obs = torch.linspace(0, 1, nt).reshape(-1, 1)
    X, T = torch.meshgrid(x_obs.squeeze(), t_obs.squeeze(), indexing='ij')
    X_flat = X.reshape(-1, 1)
    T_flat = T.reshape(-1, 1)
    grid_inputs = torch.cat([X_flat, T_flat], dim=1)
    # True solution for observed points (known nu)
    nu_true = 0.01 / np.pi
    u_obs = -torch.sin(np.pi * X_flat) * torch.exp(-np.pi**2 * nu_true * T_flat)
    return X_flat, T_flat, u_obs

# ---------------------- Training Loop ---------------------- #
def train_ipinn(model, epochs=3000, n_int=10000, n_bnd=2000, n_ini=2000, lr=1e-3):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    losses, nu_list = [], []
    # Fixed observation points for inverse loss
    X_obs, T_obs, u_obs = sample_observations(nx=50, nt=10)

    for _ in tqdm(range(epochs)):
        (x_int, t_int), (x_bnd, t_bnd), (x_ini, t_ini) = sample_training_points(n_int, n_bnd, n_ini)
        X_int = torch.cat([x_int, t_int], dim=1)
        X_bnd = torch.cat([x_bnd, t_bnd], dim=1)
        X_ini = torch.cat([x_ini, t_ini], dim=1)

        # PDE loss (interior)
        f = compute_pde_residual_ipinn(model, x_int, t_int)
        loss_pde = torch.mean(f ** 2)

        # Initial condition loss
        u_ini_pred = model(X_ini)
        u_ini_true = initial_condition(x_ini)
        loss_ini = torch.mean((u_ini_pred - u_ini_true) ** 2)

        # Boundary loss
        u_bnd_pred = model(X_bnd)
        u_bnd_true = boundary_condition(t_bnd)
        loss_bnd = torch.mean((u_bnd_pred - u_bnd_true) ** 2)

        # Observation data loss
        u_obs_pred = model(torch.cat([X_obs, T_obs], dim=1))
        loss_obs = torch.mean((u_obs_pred - u_obs) ** 2)

        # Total loss: weighted sum (you can adjust weight of obs/data term)
        total_loss = loss_pde + loss_ini + loss_bnd + 5 * loss_obs
        losses.append(total_loss.item())
        nu_list.append(model.viscosity().item())

        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()

    return losses, nu_list

# ---------------------- Prediction Grid ---------------------- #
def make_prediction_grid(nx=256, nt=100):
    x_grid = torch.linspace(-1, 1, nx).reshape(-1, 1)
    t_grid = torch.linspace(0, 1, nt).reshape(-1, 1)
    X, T = torch.meshgrid(x_grid.squeeze(), t_grid.squeeze(), indexing='ij')
    X_flat = X.reshape(-1, 1)
    T_flat = T.reshape(-1, 1)
    X_full = torch.cat([X_flat, T_flat], dim=1)
    return X, T, X_full

# ---------------------- Main Routine ---------------------- #
if __name__ == "__main__":
    torch.manual_seed(0)
    model = BurgersInversePINN()
    print("Training inverse PINN (iPINN)...")
    losses, nu_list = train_ipinn(model, epochs=3000, n_int=10000, n_bnd=2000, n_ini=2000, lr=1e-3)
    print("Training complete.")
    print(f"Estimated viscosity (nu): {model.viscosity().item():.5f}")

    # Predict over grid
    X, T, grid_inputs = make_prediction_grid()
    u_pred_ipinn = model(grid_inputs).detach().cpu().numpy().reshape(X.shape)

    # Plot
    plt.figure(figsize=(8, 6))
    plt.pcolormesh(T, X, u_pred_ipinn, shading='auto', cmap='jet')
    plt.xlabel('t')
    plt.ylabel('x')
    plt.colorbar(label='u(x, t)')
    plt.title('Inverse PINN Solution to 1D Burgers Equation')
    plt.show()

# --- 1D Plot at t=0.5 for Inverse PINN ---
    t_fixed = 0.5
    x_values = torch.linspace(-1, 1, 200).reshape(-1, 1)
    t_values = torch.ones_like(x_values) * t_fixed
    X_query = torch.cat([x_values, t_values], dim=1)
    y_pred_ipinn = model(X_query).detach().cpu().numpy()  # shape: (200, 1)

    plt.figure(figsize=(8, 5))
    plt.plot(x_values.numpy(), y_pred_ipinn[:, 0], 'r-', label='iPINN')
    plt.xlabel('x')
    plt.ylabel('u(x, t=0.5)')
    plt.title('Inverse PINN Solution at t=0.5')
    plt.legend()
    plt.grid()
    plt.show()

